{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "322a7524-c8ec-42d0-84eb-49c38399ff00",
   "metadata": {},
   "source": [
    "# -------------------------------------------------------------\n",
    "# AG2 Multi-Agent System \n",
    "# -------------------------------------------------------------"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2dc8da10-f068-4ba7-8fa0-a48be484b488",
   "metadata": {},
   "source": [
    "# Install AG2 "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "6eea740a-7e7e-4d7d-be80-edb759716ea6",
   "metadata": {},
   "outputs": [],
   "source": [
    "!pip install \"ag2[openai]\" -q\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a05808e8-666c-4c53-be14-859e71b1619e",
   "metadata": {},
   "source": [
    "# -------------------------------------------------------------\n",
    "# LLM Configuration for AG2 Multi-Agent System\n",
    "# -------------------------------------------------------------"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "73cd6b21-c6b3-4d0f-b2fe-3c4f2a3cf3ef",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " LLM configuration loaded successfully.\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "from autogen import LLMConfig\n",
    "\n",
    "llm_config = LLMConfig(config_list={\n",
    "    \"api_type\": \"openai\",      \n",
    "    \"model\": \"gpt-4o\",         \n",
    "    \"api_key\": os.environ[\"OPENAI_API_KEY\"],  \n",
    "    \"temperature\": 0.2          \n",
    "})\n",
    "\n",
    "print(\" LLM configuration loaded successfully.\")\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ce1638b7-8aa4-4e1a-8ee3-62d5677fe145",
   "metadata": {},
   "source": [
    "# -------------------------------------------------------------\n",
    "# Context Variables and Agent Skeletons\n",
    "# -------------------------------------------------------------"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "c25ba79a-62c7-4b7d-b9fd-eb65cae64c8d",
   "metadata": {},
   "outputs": [],
   "source": [
    "from autogen.agentchat.group import ContextVariables\n",
    "from autogen import ConversableAgent\n",
    "\n",
    "context_variables = ContextVariables(data={\n",
    "    \"user_query\": None,          \n",
    "    \"explained_terms\": None,      \n",
    "    \"mp_query\": None,            \n",
    "    \"mp_results\": None,           \n",
    "    \"final_conclusion\": None      \n",
    "})\n",
    "\n",
    "\n",
    "agent_explainer = ConversableAgent(\n",
    "    name=\"AgentA_Explainer\",\n",
    "    system_message=(\n",
    "        \"You are Agent A (Explainer). \"\n",
    "        \"Your job is to interpret the user's material design query, \"\n",
    "        \"explain technical terms such as bandgap or crystal structure, \"\n",
    "        \"and save your summary in context_variables['explained_terms']. \"\n",
    "        \"Do not perform external searches.\"\n",
    "    ),\n",
    "    llm_config=llm_config,\n",
    "    human_input_mode=\"NEVER\",\n",
    ")\n",
    "\n",
    "agent_retriever = ConversableAgent(\n",
    "    name=\"AgentB_MaterialsRetriever\",\n",
    "    system_message=(\n",
    "        \"You are Agent B (Retriever). \"\n",
    "        \"Using both the user's query and Agent A's explanation, \"\n",
    "        \"formulate a structured query for the Materials Project API, \"\n",
    "        \"store it in context_variables['mp_query'], \"\n",
    "        \"retrieve the materials, and store the raw results in \"\n",
    "        \"context_variables['mp_results'].\"\n",
    "    ),\n",
    "    llm_config=llm_config,\n",
    "    human_input_mode=\"NEVER\",\n",
    ")\n",
    "\n",
    "agent_analyzer = ConversableAgent(\n",
    "    name=\"AgentC_Analyzer\",\n",
    "    system_message=(\n",
    "        \"You are Agent C (Analyzer). \"\n",
    "        \"Analyze the retrieved materials in context_variables['mp_results'], \"\n",
    "        \"extract insights about which materials meet the criteria (e.g., bandgap > 3), \"\n",
    "        \"and write your summary in context_variables['final_conclusion'].\"\n",
    "    ),\n",
    "    llm_config=llm_config,\n",
    "    human_input_mode=\"NEVER\",\n",
    ")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0b02c7a5-fffa-4b9a-9d33-336482bed92e",
   "metadata": {},
   "source": [
    "# -------------------------------------------------------------\n",
    "# Materials Project Tool integration \n",
    "# -------------------------------------------------------------"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "a8182be0-5945-42d6-aada-3b06f6afe91a",
   "metadata": {},
   "outputs": [],
   "source": [
    "from autogen.tools import tool\n",
    "from pymatgen.ext.matproj import MPRester\n",
    "import os\n",
    "\n",
    "@tool(name=\"materials_project_query\", description=\"Retrieve materials from the Materials Project database.\")\n",
    "def materials_project_query(criteria: dict, properties: list):\n",
    "    \"\"\"\n",
    "    Queries the Materials Project database for materials that match the given criteria.\n",
    "    \"\"\"\n",
    "    api_key = os.getenv(\"MP_API_KEY\")\n",
    "    if not api_key:\n",
    "        raise ValueError(\"Materials Project API key not found. Please set MP_API_KEY in your environment.\")\n",
    "    \n",
    "    with MPRester(api_key) as mpr:\n",
    "        results = mpr.query(criteria=criteria, properties=properties)\n",
    "    return results\n",
    "\n",
    "\n",
    "# Recreate Agent B (Retriever) with the updated system message referencing the tool\n",
    "from autogen import ConversableAgent\n",
    "\n",
    "agent_retriever = ConversableAgent(\n",
    "    name=\"AgentB_MaterialsRetriever\",\n",
    "    system_message=(\n",
    "        \"You are Agent B (Retriever). \"\n",
    "        \"Using the user's query and Agent A's explanation, \"\n",
    "        \"you must call the tool 'materials_project_query' to query the Materials Project API. \"\n",
    "        \"Store the query in context_variables['mp_query'] \"\n",
    "        \"and the retrieved results in context_variables['mp_results'].\"\n",
    "    ),\n",
    "    llm_config=llm_config,\n",
    "    human_input_mode=\"NEVER\",\n",
    ")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fdaa4bdb-5c71-4dc2-aae7-c5c798e155d7",
   "metadata": {},
   "source": [
    "# -------------------------------------------------------------\n",
    "# Group Chat Configuration\n",
    "# -------------------------------------------------------------"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "1dc794d0-ddff-4ad4-a273-b8857c15ec77",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdin",
     "output_type": "stream",
     "text": [
      "Enter your material design challenge:  Give me a material with high thermal conductivity and low density\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[33mAgentA_Explainer\u001b[0m (to chat_manager):\n",
      "\n",
      "Give me a material with high thermal conductivity and low density\n",
      "\n",
      "--------------------------------------------------------------------------------\n",
      "\u001b[32m\n",
      "Next speaker: AgentB_MaterialsRetriever\n",
      "\u001b[0m\n",
      "\u001b[33mAgentB_MaterialsRetriever\u001b[0m (to chat_manager):\n",
      "\n",
      "To find a material with high thermal conductivity and low density, we can query the Materials Project database for materials that have these properties. High thermal conductivity is often desired in applications requiring efficient heat dissipation, while low density is beneficial for lightweight applications.\n",
      "\n",
      "Let's define the query parameters:\n",
      "- High thermal conductivity: We can set a minimum threshold, for example, greater than 100 W/mK.\n",
      "- Low density: We can set a maximum threshold, for example, less than 5 g/cm³.\n",
      "\n",
      "I'll perform the query to find materials that meet these criteria.\n",
      "\n",
      "--------------------------------------------------------------------------------\n",
      "\u001b[32m\n",
      "Next speaker: AgentC_Analyzer\n",
      "\u001b[0m\n",
      "\u001b[33mAgentC_Analyzer\u001b[0m (to chat_manager):\n",
      "\n",
      "Please provide the results from the Materials Project database so I can analyze them and determine which materials meet the specified criteria.\n",
      "\n",
      "--------------------------------------------------------------------------------\n",
      "\u001b[31m\n",
      ">>>>>>>> TERMINATING RUN (fd0c67da-cbdb-48e5-b781-2ffa34861a5f): Maximum rounds (3) reached\u001b[0m\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "ChatResult(chat_id=34491863457445640635370706002703372202, chat_history=[{'content': 'Give me a material with high thermal conductivity and low density', 'role': 'assistant', 'name': 'AgentA_Explainer'}, {'content': \"To find a material with high thermal conductivity and low density, we can query the Materials Project database for materials that have these properties. High thermal conductivity is often desired in applications requiring efficient heat dissipation, while low density is beneficial for lightweight applications.\\n\\nLet's define the query parameters:\\n- High thermal conductivity: We can set a minimum threshold, for example, greater than 100 W/mK.\\n- Low density: We can set a maximum threshold, for example, less than 5 g/cm³.\\n\\nI'll perform the query to find materials that meet these criteria.\", 'name': 'AgentB_MaterialsRetriever', 'role': 'user'}, {'content': 'Please provide the results from the Materials Project database so I can analyze them and determine which materials meet the specified criteria.', 'name': 'AgentC_Analyzer', 'role': 'user'}], summary='Please provide the results from the Materials Project database so I can analyze them and determine which materials meet the specified criteria.', cost={'usage_including_cached_inference': {'total_cost': 0}, 'usage_excluding_cached_inference': {'total_cost': 0}}, human_input=[])"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "from autogen.agentchat.groupchat import GroupChat, GroupChatManager\n",
    "\n",
    "# GroupChat \n",
    "group_chat = GroupChat(\n",
    "    agents=[agent_explainer, agent_retriever, agent_analyzer],\n",
    "    speaker_selection_method=\"round_robin\" ,\n",
    "    max_round=3                              \n",
    ")\n",
    "\n",
    "# GroupChatManager \n",
    "manager = GroupChatManager(groupchat=group_chat, llm_config=llm_config)\n",
    "\n",
    "# Store the user query in context variables \n",
    "user_query = input(\"Enter your material design challenge: \")\n",
    "\n",
    "\n",
    "context_variables[\"user_query\"] = user_query\n",
    "\n",
    "# Start the conversation FROM Agent A, sending the message to the manager\n",
    "\n",
    "agent_explainer.initiate_chat(\n",
    "    manager,\n",
    "    message=user_query,\n",
    "    context_variables=context_variables\n",
    ")\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "85821ed8-4d0b-4d6c-80ba-b9d501248baf",
   "metadata": {},
   "source": [
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c15a7ad0-e6b6-49ab-b1e9-6d072ce56e12",
   "metadata": {},
   "outputs": [],
   "source": [
    "Give me a material with high thermal conductivity and low density\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
